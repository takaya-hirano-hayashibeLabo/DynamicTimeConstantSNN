train:
  batch: 64
  epoch: 200
  iter: -1 #if -1, train until max. for testing, set to 2
  lr: 0.001
  save_interval: 100 #every epoch
  datatype: ur5e
  datapath: original-data/Trajectory/datasets.csv #relative path below ROOT
  sequence: 50 #limit the sequence
  timescales: [1.0] #only learn 1x
  schedule-step: -1 #if -1, no schedule
  schedule-rate: 0.5

model:
  type: snn

  in-size: 1200
  hiddens: [512,128,64]
  out-size: &out_size 12
  clip-norm: &clip_norm 1.0 #maximum gradient for gradient clipping. usually 1.0
  dropout: &dropout 0.2

  dt: 0.03 #s
  init-tau: 0.6 #keep 95% of the past steps
  min-tau: 0.03
  train-tau: true #learn tau
  v-threshold: 0.1
  v-rest: 0.0
  reset-mechanism: zero
  spike-grad: fast-sigmoid
  output-membrane: true #use membrane potential for prediction
  reset-outmem: false #do not reset the last layer of DynaLif
  

output-model: #continuous value prediction model
  out-type: velocity
  in-size: *out_size
  hiddens: [16,16,16]
  out-size: 2
  dropout: *dropout
  clip-norm: *clip_norm
  out-actf: identity #{identity,tanh}


encoder:
  type: THR #Threshold model
  resolution: 200 #resolution of threshold
  thr-max: 1.1
  thr-min: -1.1